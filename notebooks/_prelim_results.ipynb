{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit Testing\n",
    "\n",
    "This notebook uses visual representations to check the the dimentions of each input and output.\n",
    "\n",
    "Then, we test different methods for unpacking the linear layer at the end of the recurrent mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S_X0tOlZa6Yc",
    "outputId": "d9a1c78c-0cb9-4765-af76-269254542425"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jackb/columbia/TFJ-DRL-update1/src/main\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys, os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import talib as ta\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# MAKE SURE WE HAVE THE ENVIRONMENT CONFIGURED PROPERLY\n",
    "%cd ../src/main\n",
    "SCRIPT_DIR = os.path.dirname(os.path.abspath(\".\"))\n",
    "if 'backend' not in os.listdir('.'):\n",
    "    sys.path.insert(0, os.path.abspath(SCRIPT_DIR))\n",
    "\n",
    "from backend.utils import DataIterGen, DataIterGen_V2\n",
    "from backend.technical_analysis import get_data_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "TBzCQdBka6Yi"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(f'cuda:{torch.cuda.device_count()-1}')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "\n",
    "NAME = \"DLRL_conf_\"\n",
    "ENV_SIZE = 128\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded previous generation\n",
      "Loaded dataset of 39 tickers, 664 ticks, 86 features/tick.\n"
     ]
    }
   ],
   "source": [
    "#Data Generation\n",
    "\n",
    "stockList1=['COO','COF','ABBV','CCL','AMD','GOOG',\n",
    "            'ABT','ACN','ADBE','AES','NVDA',\n",
    "            'AIG','ALL', 'AMG','AMZN','APA','AAPL',\n",
    "            'AXP','BA','BBY','CAT','GE', 'CSCO', \n",
    "            'EA','EQR','FCX','FE',\n",
    "            'HST','IBM','INTC','JCI','MMM','MO',\n",
    "            'ORCL','PPL','T','EXPD','VMC','VNO']\n",
    "if 'stock_dataset.npy' in os.listdir('../data'):\n",
    "    full_list = np.load(file='../data/stock_dataset.npy')\n",
    "    print(\"Loaded previous generation\")\n",
    "else:\n",
    "    print(\"Generating new dataset\")\n",
    "    full_list=get_data_set(stockList1, start=\"2017-01-01\", end=\"2020-01-01\", verbose=True, coint_threshold=0.1)\n",
    "    np.save(file='../data/stock_dataset.npy', arr=full_list)\n",
    "\n",
    "print(f\"Loaded dataset of {full_list.shape[0]} tickers, {full_list.shape[1]} ticks, {full_list.shape[2]} features/tick.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definining the recurrent attention (supervised) model\n",
    "\n",
    "We will modify the feed-forward (`nn.Linear`) portion of the model to return the latent representation of the price at $t+1$\n",
    "\n",
    "Before we have $W_1 \\in \\mathbb{R^{256 \\times \\text{env\\_size}}}$, $W_2 \\in \\mathbb{R^{\\text{env\\_size} \\times \\text{1}}}$:\n",
    "\n",
    "$$\\hat{\\text{price}}_{t+1} = RELU(W_1 \\cdot (h_t \\oplus \\text{attention}(h_t)))W_2$$\n",
    "\n",
    "\n",
    "To 'crack open' the model we will change its forward function to return the hidden vector $RELU(W_1 \\cdot (h_t \\oplus \\text{attention}(h_t)))$. This is primarily what we will test on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Kt9S_tgDa6Yi"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GRU(\n",
       "  (rnn): GRU(86, 128, batch_first=True)\n",
       "  (linear1): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (linear2): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from backend.reinforcement_learning import tam\n",
    "\n",
    "#define GRU class\n",
    "#init parameter: env_size for RL algorithm\n",
    "class GRU(nn.Module):\n",
    "    def __init__(self, env_size):\n",
    "        super(GRU, self).__init__()\n",
    "        self.rnn=nn.GRU(\n",
    "            input_size=86,\n",
    "            hidden_size=128,\n",
    "            num_layers=1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.linear1=nn.Linear(256, env_size)\n",
    "        self.linear2=nn.Linear(env_size, 1)\n",
    "        self.num_layers=1\n",
    "        \n",
    "    def forward(self, x, state, device):\n",
    "        batch_size,timestep, _=x.shape\n",
    "        states, state=self.rnn(x, state)\n",
    "        tamVec=tam(states, device)\n",
    "        \n",
    "        #concatVec: batch_size, time_step, hidden_size*2\n",
    "        #i.e.       batch_size, 24       , 256        \n",
    "        concatVec=torch.cat([states, tamVec],axis=2)\n",
    "        envVec=self.linear1(torch.tanh(concatVec.reshape(batch_size*timestep, -1)))\n",
    "        output=nn.Dropout(p=0.3)(envVec)\n",
    "        output=nn.ReLU()(output)\n",
    "        # hidden_output=nn.ReLU()(output) # HERE\n",
    "        output=self.linear2(output)\n",
    "        envVec=envVec.reshape(batch_size, timestep, -1)\n",
    "        return (output.view(batch_size, -1), envVec), state#, hidden_output\n",
    "  \n",
    "    def begin_state(self, device, batch_size=1): \n",
    "        # `nn.GRU` takes a tensor as hidden state\n",
    "        return torch.zeros((\n",
    "                    self.rnn.num_layers, batch_size, 128), device=device)\n",
    "\n",
    "tam_gru = GRU(env_size=ENV_SIZE).to(DEVICE)\n",
    "tam_gru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to redefine the `rlPolicy` agent as well. The `rlPolicy` agent is the one which recieves the loss at a given timestep $t$ during training, so it needs to pass that loss backwards to the `tam_gru` model as well.\n",
    "\n",
    "Between the `tam_gru` model and policy agent we add a decoder model which reconstructs the `hidden_state` vector from the `hidden_output` vector.\n",
    "\n",
    "To train the decoder, need a new loss function on top of the loss function from the paper. This new loss will be the angular difference between the `hidden_output` vector and the `predicted_hidden_output` vector. As we track this loss through time, it may clue us in to the `tam_gru` model's ability to represent the state. Higher loss means the `tam_gru` is treading uncharted territory, so to speak, which makes the policy agent ***confused***. This is how the decoder loss functions as a confusion metric for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoEncoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=3072, out_features=64, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Dropout(p=0.3, inplace=False)\n",
       "    (3): Linear(in_features=64, out_features=16, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=16, out_features=2, bias=True)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=2, out_features=16, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Dropout(p=0.3, inplace=False)\n",
       "    (3): Linear(in_features=16, out_features=64, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=64, out_features=3072, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    \"\"\"Auto-encoder to get a latent representation of the hidden state, \n",
    "    then decode to get the confusion\"\"\"\n",
    "    def __init__(self, env_size, device: torch.device):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "           nn.Linear(env_size*24, 64),\n",
    "           nn.LeakyReLU(),\n",
    "           nn.Dropout(p=0.3),\n",
    "           nn.Linear(64, 16),\n",
    "           nn.ReLU(),\n",
    "           nn.Linear(16, 2)\n",
    "        )\n",
    "\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "           nn.Linear(2, 16),\n",
    "           nn.LeakyReLU(),\n",
    "           nn.Dropout(p=0.3),\n",
    "           nn.Linear(16, 64),\n",
    "           nn.ReLU(),\n",
    "           nn.Linear(64, env_size*24)\n",
    "       )\n",
    "       \n",
    "        self.env_size = env_size\n",
    "    \n",
    "    def forward(self, x):\n",
    "        bsize = x.shape[0]\n",
    "        x = x.flatten(start_dim=1)\n",
    "        hidden = self.encoder(x)\n",
    "        output = self.decoder(hidden)\n",
    "        output = output.reshape(bsize, 24, self.env_size)\n",
    "        hidden = hidden.reshape(bsize, 1, 2)\n",
    "        return hidden, output\n",
    "\n",
    "decoder = AutoEncoder(ENV_SIZE, DEVICE).to(DEVICE)\n",
    "decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Monty class\n",
    "\n",
    "class extending nn.Module containing an instance of both the policy agent and gru-tam model.\n",
    "\n",
    "Intended to make training easier to implement with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "full_monty(\n",
       "  (rnn): GRU(\n",
       "    (rnn): GRU(86, 128, batch_first=True)\n",
       "    (linear1): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (linear2): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from backend.reinforcement_learning import get_params, rlForwardFunc\n",
    "\n",
    "class full_monty(nn.Module):\n",
    "    \"\"\"RL Policy net modeled by parameters\"\"\"\n",
    "    def __init__(self, env_size, device: torch.device):\n",
    "        super(full_monty, self).__init__()\n",
    "        \n",
    "        #self.linear = nn.Linear(32+1, 1)\n",
    "        \n",
    "        W, b, h=get_params(env_size, device)\n",
    "        self.device=device\n",
    "        self.W=nn.Parameter(W)\n",
    "        self.b=nn.Parameter(b)\n",
    "        self.h=nn.Parameter(h)\n",
    "        self.rnn=GRU(env_size)\n",
    "\n",
    "    # Forward pass through the RL Policy network\n",
    "    def forward(self, x, state):\n",
    "        # Obtain predictions and environment vector from GRU\n",
    "        (predP, envVec), state = self.rnn(x, state, self.device)\n",
    "        \n",
    "        # Compute actions based on the environment vector and parameters\n",
    "        output = rlForwardFunc(envVec, [self.W, self.b, self.h])\n",
    "        \n",
    "        # Return predictions and actions\n",
    "        return predP, output, envVec.clone().detach()\n",
    "    \n",
    "    # Initialize the hidden state for the RL Policy network\n",
    "    def begin_state(self, device, batch_size=1):\n",
    "        return self.rnn.begin_state(device, batch_size)\n",
    "\n",
    "combined = full_monty(ENV_SIZE, DEVICE)\n",
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear global variables to save memory / for good taste\n",
    "del combined\n",
    "del tam_gru\n",
    "del decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility function defined in paper. \n",
    "\n",
    "$$R_t = \\delta _t z_t - c|\\delta_t - \\delta_{t-1}| $$\n",
    "\n",
    "$$U_t = \\sum_{t=1}^T R_t$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from backend.utils import calcUtility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "HVHG_bRUa6Yk"
   },
   "outputs": [],
   "source": [
    "from backend.utils import grad_clipping, init_weights, lossFunc, lossFunc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the new training function\n",
    "\n",
    "Implicitly, we have 3 global models working together.\n",
    "\n",
    "* `tam_gru`\n",
    "* `decoder`\n",
    "* `policy_agent`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ly7ecW78a6Yl"
   },
   "outputs": [],
   "source": [
    "#trainer for epoch\n",
    "def train_epoch(train_iter, net, device, optim1, optim3, lossfn):\n",
    "    loss_data=[]\n",
    "    embed_list = []\n",
    "    confusion_list = []\n",
    "    with torch.autograd.set_detect_anomaly(True):\n",
    "        for X, y, z, _ in train_iter:\n",
    "            # reset state for each batch\n",
    "            state= net.begin_state(batch_size=X.shape[0], device=device)\n",
    "        \n",
    "            # move to device\n",
    "            X, y, z=X.to(device), y.to(device), z.to(device)\n",
    "            \n",
    "            # doing tam_gru\n",
    "            predP, output, envVec = net(X, state) \n",
    "            \n",
    "            # ============[ ADDING DECODER LOSS CONFUSION, DREAM] =====================\n",
    "            decode_tensor = envVec.clone().detach()\n",
    "            embed, dream = decoder(decode_tensor)\n",
    "            bsize, tstep = dream.shape[0], dream.shape[1]\n",
    "            confusion = nn.CosineEmbeddingLoss()(dream.view((bsize * tstep, -1)), decode_tensor.view((bsize * tstep, -1)), torch.ones((bsize*tstep)).to(device))\n",
    "            optim3.zero_grad()\n",
    "            confusion.backward()\n",
    "            optim3.step()\n",
    "            # =========================================================================\n",
    "\n",
    "            loss = lossfn(predP, y, output,z, device)\n",
    "            optim1.zero_grad()\n",
    "            loss.backward()\n",
    "            grad_clipping(net, 1)\n",
    "            optim1.step()\n",
    "            loss_data.append(loss.item())\n",
    "    return np.array(loss_data).mean(), loss_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "39OBubURa6Ym"
   },
   "outputs": [],
   "source": [
    "#Testing on trained model\n",
    "def prediction(eval_iter, net, device, lossfn):\n",
    "    net.eval()\n",
    "    decoder.eval()\n",
    "    loss_list=[]\n",
    "    U_list=[]\n",
    "    embed_list=[]\n",
    "    confusion_list=[]\n",
    "    with torch.no_grad():\n",
    "        for X, y, z, _ in eval_iter:\n",
    "            # to device\n",
    "            X, y, z = X.to(device), y.to(device), z.to(device)\n",
    "\n",
    "            # initialize rnn state\n",
    "            state=net.begin_state(batch_size=X.shape[0], device=device) # changed from net.begin\n",
    "\n",
    "            # feed through full-monty\n",
    "            predP, output, envVec = net(X, state)\n",
    "\n",
    "            # ============[ ADDING DECODER LOSS CONFUSION, DREAM] =====================\n",
    "            env_cpy = envVec.clone().detach()\n",
    "            embed, dream = decoder(env_cpy) # adding the embedding address, dream state \n",
    "            bsize, tstep = dream.shape[0], dream.shape[1]\n",
    "            confusion = nn.CosineEmbeddingLoss()(dream.view((bsize * tstep, -1)), env_cpy.view((bsize * tstep, -1)), torch.ones((bsize*tstep)).to(device))\n",
    "            # =========================================================================\n",
    "\n",
    "            loss=lossfn(predP, y, output, z, device).float()\n",
    "            U, _=calcUtility(output, z)\n",
    "            loss_list.append(loss.cpu().numpy())\n",
    "            U_list.append(U[:, -1].mean().cpu().numpy())\n",
    "            embed_list.append(embed.flatten(0, 1).cpu().numpy())\n",
    "            confusion_list.append(confusion.cpu().numpy())\n",
    "    return np.array(loss_list).mean(), np.array(U_list).mean(), np.concatenate(embed_list), np.array(confusion_list).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "4zTVLtNGa6Yl"
   },
   "outputs": [],
   "source": [
    "import imageio\n",
    "#Trainer \n",
    "#Incoporated learning rate scheduler\n",
    "#Avg training loss & Avg validation Utility gain is recorded on epoch basis\n",
    "#Loss and Utility by epoch are plotted at the end of training\n",
    "def train(train_iter, eval_iter, net, optimizer1, optimizer2, device, num_epoch, name, lossfn=lossFunc2):\n",
    "    loss_data=[]\n",
    "    U_data=[]\n",
    "    image_files = []\n",
    "    os.makedirs('training_pics', exist_ok=True)\n",
    "    net.apply(init_weights)\n",
    "    net.to(device)\n",
    "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer1, 0.95, last_epoch=-1)\n",
    "\n",
    "    for epoch in range(num_epoch):\n",
    "        net.train(), decoder.train()\n",
    "        lossEpoch, lossEpoch_list =train_epoch(train_iter, net, device, optimizer1, optimizer2, lossfn=lossfn)   \n",
    "        loss_v, U_v, embeds, confusion=prediction(eval_iter, net, device, lossfn=lossfn)\n",
    "        loss_data.append(lossEpoch)  \n",
    "        U_data.append(U_v)\n",
    "        print(f'Epoch {epoch}, training loss: {lossEpoch:.2f}, val utility: {U_v:.2f}, confusion: {confusion:.3f}')\n",
    "        plt.figure()\n",
    "        x, y = embeds[:, 0], embeds[:, 1]\n",
    "        plt.scatter(x,y, alpha=0.25)\n",
    "        image_file = f\"epoch_{epoch + 1}.png\"\n",
    "        plt.savefig('training_pics/'+image_file)\n",
    "        plt.close()\n",
    "        image_files.append(image_file)\n",
    "        torch.save(net.state_dict(), os.path.join('./model_weights', f'{name}-epoch-{epoch+1}.pth'))\n",
    "        torch.save(decoder.state_dict(), os.path.join('./model_weights', f'{name}_decoder-{epoch+1}.pth'))\n",
    "        scheduler.step()\n",
    "    \n",
    "     \n",
    "    # Create GIF\n",
    "    #plot gif of training process\n",
    "    gif_file = 'training_progress.gif'\n",
    "    with imageio.get_writer(gif_file, mode='I', duration=0.5) as writer:\n",
    "        for image_file in image_files:\n",
    "            image = imageio.imread('training_pics/'+image_file)\n",
    "            writer.append_data(image)\n",
    "\n",
    "    # Clean up images\n",
    "    for image_file in image_files:\n",
    "        os.remove('training_pics/'+image_file)\n",
    "\n",
    "    #plot loss & Utility\n",
    "    fig, ax_left = plt.subplots(figsize=(10,4))\n",
    "    ax_right = ax_left.twinx()\n",
    "    ax_left.plot(loss_data, label = \"Loss\", color='blue')\n",
    "    ax_right.plot(U_data, label = \"Utility\", color='red')\n",
    "    ax_left.set_xlabel('Time Step')\n",
    "    ax_right.set_ylabel('Loss y axis')\n",
    "    ax_right.set_ylabel('Utility y axis')\n",
    "    ax_left.set_title('Loss and Utility')\n",
    "    ax_left.legend()\n",
    "    ax_right.legend()\n",
    "    return loss_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "NKzxSmYohHkA"
   },
   "outputs": [],
   "source": [
    "def test(net, conf_net, test_iter, device, epoch, name):\n",
    "    net.eval()\n",
    "    net.load_state_dict(torch.load(os.path.join('./model_weights', f'{name}-epoch-{epoch}.pth')))\n",
    "    net.to(device)\n",
    "    conf_net.eval()\n",
    "    conf_net.load_state_dict(torch.load(os.path.join('./model_weights', f'{name}_decoder-{epoch}.pth')))\n",
    "    conf_net.to(device)\n",
    "\n",
    "    U_list=[]\n",
    "    conf_list=[]\n",
    "    with torch.no_grad():\n",
    "        for X, _, _, zp in test_iter:\n",
    "            X, zp = X.to(device),  zp.to(device)\n",
    "            state=net.begin_state(batch_size=X.shape[0], device=device)\n",
    "            _, output, envVec=net(X, state)\n",
    "            U, _=calcUtility(output, zp)\n",
    "            U_list.append(U[:, -1].mean().cpu().numpy())\n",
    "\n",
    "            #== [confusion] ==\n",
    "            _, dream = conf_net(envVec)\n",
    "            bsize, tstep = dream.shape[0], dream.shape[1]\n",
    "            confusion = nn.CosineEmbeddingLoss()(dream.view((bsize * tstep, -1)), envVec.view((bsize * tstep, -1)), torch.ones((bsize*tstep)).to(device))\n",
    "            conf_list.append(confusion.cpu().numpy())\n",
    "            # ===============\n",
    "    return np.array(U_list).mean(), np.array(conf_list).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "xwNddm681EtG"
   },
   "outputs": [],
   "source": [
    "\n",
    "def demo(net: torch.nn.Module, conf_net: torch.nn.Module, demo_iter, device: torch.device, epoch, name):\n",
    "    net.eval()\n",
    "    net.load_state_dict(torch.load(os.path.join('./model_weights', f'{name}-epoch-{epoch}.pth')))\n",
    "    net.to(device)\n",
    "    conf_net.eval()\n",
    "    conf_net.load_state_dict(torch.load(os.path.join('./model_weights', f'{name}_decoder-{epoch}.pth')))\n",
    "    conf_net.to(device)\n",
    "    \n",
    "    reward=np.array([])\n",
    "    conf_list=np.array([])\n",
    "    with torch.no_grad():\n",
    "        for X, _, _, zp in demo_iter:\n",
    "            X, zp = X.to(device),  zp.to(device)\n",
    "            state=net.begin_state(batch_size=X.shape[0], device=device)\n",
    "            _, output, envVec=net(X, state)\n",
    "            discretizedAction=((output>=0)*2-1)\n",
    "            batchReward=discretizedAction*zp\n",
    "            reward=np.concatenate((reward,batchReward[:,-1].reshape(-1).cpu().numpy()))\n",
    "            \n",
    "            #== [confusion] ==\n",
    "            _, dream = conf_net(envVec)\n",
    "            bsize, tstep = dream.shape[0], dream.shape[1]\n",
    "            confusion = [nn.CosineEmbeddingLoss()(dream[i,:,:], envVec[i,:,:], torch.ones((1)).to(device)).item() for i in range(bsize)]\n",
    "            conf_list = np.concatenate((conf_list, np.array(confusion)))\n",
    "            # ===============\n",
    "            \n",
    "        result = [sum(reward[ : i + 1]) for i in range(len(reward))] \n",
    "    fig, [ax_left, ax_right] = plt.subplots(2, figsize=(20,4), sharex=True)\n",
    "    ax_left.plot(result, label = \"Stock Gain\", color='blue')\n",
    "    ax_left.hlines([0], 0, 1, transform=ax_left.get_yaxis_transform(), linestyle='dashed', colors='gray')\n",
    "    ax_left.set_xlabel('Time Step')\n",
    "    ax_left.set_ylabel('Cumulative Gain')\n",
    "    ax_right.set_ylabel('Confusion')\n",
    "    ax_right.plot(conf_list, label='Confusion at Time Step')\n",
    "    ax_left.set_title('Demonstration of Algorithm')\n",
    "    ax_left.legend()\n",
    "    ax_right.legend()\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, Test and Demo with Cooper Companies Inc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jdzMUcEBwD7h",
    "outputId": "00541867-4fe9-48c7-9128-0171c0846e27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using periods\n",
      "Train: ('2013-01-01', '2017-10-01')\n",
      "Test: ('2018-01-01', '2019-01-01')\n",
      "Validation: ('2017-10-08', '2018-04-01')\n",
      "Stock ticker: COO\n"
     ]
    }
   ],
   "source": [
    "#train_iter, val_iter, test_iter=DataIterGen([0, 1]1, [4, 2, 3], stockList1, full_list)\n",
    "train_iter, val_iter, test_iter = DataIterGen_V2(0, stockList1, demo=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Y4zf3LhWLoTd",
    "outputId": "a433bfbc-c654-4b46-edd9-b50204a38958"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'decoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m MAX_EPOCH \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m45\u001b[39m\n\u001b[1;32m      5\u001b[0m optim1 \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(net\u001b[38;5;241m.\u001b[39mparameters(),       lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.00006\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.02\u001b[39m, eps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m optim2 \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(\u001b[43mdecoder\u001b[49m\u001b[38;5;241m.\u001b[39mparameters(),   lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m      7\u001b[0m loss\u001b[38;5;241m=\u001b[39mtrain(train_iter, val_iter, net\u001b[38;5;241m=\u001b[39mcombined, optimizer1\u001b[38;5;241m=\u001b[39moptim1, optimizer2\u001b[38;5;241m=\u001b[39moptim2, device\u001b[38;5;241m=\u001b[39mDEVICE, num_epoch\u001b[38;5;241m=\u001b[39mMAX_EPOCH, name\u001b[38;5;241m=\u001b[39mNAME)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'decoder' is not defined"
     ]
    }
   ],
   "source": [
    "#Training in action\n",
    "os.makedirs('./model_weights', exist_ok=True)\n",
    "net = full_monty(device=DEVICE, env_size=ENV_SIZE)\n",
    "MAX_EPOCH = 45\n",
    "optim1 = optim.Adam(net.parameters(),       lr=0.00006, weight_decay=0.02, eps=1e-5)\n",
    "optim2 = optim.Adam(decoder.parameters(),   lr=0.001, weight_decay=0.01)\n",
    "loss=train(train_iter, val_iter, net=combined, optimizer1=optim1, optimizer2=optim2, device=DEVICE, num_epoch=MAX_EPOCH, name=NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display gif learning feature representations\n",
    "from IPython.display import display, Image\n",
    "display(Image(filename='training_progress.gif'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "id": "0adXRQTfMJg1",
    "outputId": "c928148f-918b-43c4-d8f5-cec62d871ce1"
   },
   "outputs": [],
   "source": [
    "avgReturn, avgConf=test(net=combined, conf_net=decoder, test_iter=test_iter, device=DEVICE, epoch=MAX_EPOCH, name=NAME)\n",
    "print(f'On average, every 24 days the algorithm yields: {avgReturn:.2f}' )\n",
    "print(f'The average confusion level is: {avgConf:.3f}')\n",
    "demo_iter=DataIterGen_V2(0, stockList1, full_list, demo=True)\n",
    "demo(net=combined, conf_net=decoder, demo_iter=demo_iter, device=DEVICE, epoch=MAX_EPOCH , name=NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, Test and Demo with Capital One Financial Corp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, val_iter, test_iter = DataIterGen_V2(1, stockList1, demo=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "id": "lg5BLWG3BZa0",
    "outputId": "7b7f2995-7a66-4714-eeab-6de61054c950"
   },
   "outputs": [],
   "source": [
    "# avgReturn=test(net, test_iter, device, 4, NAME)\n",
    "# print(f'On average, every 24 days the algorithm yields:{avgReturn}' )\n",
    "demo_iter=DataIterGen([0], [], stockList1,full_list, demo=True)\n",
    "demo(net=combined, conf_net=decoder, demo_iter=demo_iter , device=DEVICE, epoch=MAX_EPOCH, name=NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Project 2 One Hot.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
